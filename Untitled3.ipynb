{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5MuDNXRqcT36EDKzh0eKJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s10nenok/mnist/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "vJ5Sm3XLNgs3"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from torchvision import transforms, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import random \n",
        "import math\n",
        "import cv2\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "\n",
        "train = datasets.MNIST('', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor()\n",
        "                       ]))\n",
        "\n",
        "test = datasets.MNIST('', train=False, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor()\n",
        "                       ]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_train():\n",
        "    reorder_type = np.dtype(np.int32).newbyteorder('>')\n",
        "    way = 'MNIST/raw/'\n",
        "    tr_im_way = way+'train-images-idx3-ubyte.gz'\n",
        "    tr_im = gzip.open(tr_im_way,'r')            \n",
        "    image_magic_number = np.frombuffer(tr_im.read(4), dtype=reorder_type)[0]\n",
        "    num_images = np.frombuffer(tr_im.read(4), dtype=reorder_type)[0]\n",
        "    image_rows = np.frombuffer(tr_im.read(4), dtype=reorder_type)[0]\n",
        "    image_columns = np.frombuffer(tr_im.read(4), dtype=reorder_type)[0]\n",
        "    buffer = tr_im.read(num_images * image_rows * image_columns)\n",
        "    images = np.frombuffer(buffer, dtype = np.uint8).astype(np.float32)\n",
        "    images = np.reshape(images, (num_images, 28,28))\n",
        "    images = images/255\n",
        "    images = torch.tensor(images)   \n",
        "    tr_im.close()\n",
        " \n",
        "    tr_lb_way = way+'train-labels-idx1-ubyte.gz'\n",
        "    tr_lb = gzip.open(tr_lb_way,'r')\n",
        "    label_magic_number = np.frombuffer(tr_lb.read(4), dtype=reorder_type).astype(np.int64)[0]\n",
        "    num_labels = np.frombuffer(tr_lb.read(4), dtype=reorder_type).astype(np.int64)[0]\n",
        "    buffer = tr_lb.read(num_labels)\n",
        "    labels = np.frombuffer(buffer, dtype = np.uint8)\n",
        "    labels = torch.tensor(labels, dtype = torch.long)\n",
        "    tr_lb.close()\n",
        "\n",
        "    permutation = np.random.permutation(len(labels)) \n",
        "    images = images[permutation] \n",
        "    labels = labels[permutation]\n",
        "\n",
        "    for i in range(len(labels)):    \n",
        "      images[i] = rotate(images[i])\n",
        "      images[i] = noise(images[i])\n",
        "      \n",
        "    return images,labels"
      ],
      "metadata": {
        "id": "8PWd23YNPt_a"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_test():\n",
        "    reorder_type = np.dtype(np.int32).newbyteorder('>')\n",
        "    way = 'MNIST/raw/'\n",
        "    tr_im_way = way+'t10k-images-idx3-ubyte.gz'\n",
        "    tr_im = gzip.open(tr_im_way,'r')            \n",
        "    image_magic_number = np.frombuffer(tr_im.read(4), dtype=reorder_type)[0]\n",
        "    num_images = np.frombuffer(tr_im.read(4), dtype=reorder_type)[0]\n",
        "    image_rows = np.frombuffer(tr_im.read(4), dtype=reorder_type)[0]\n",
        "    image_columns = np.frombuffer(tr_im.read(4), dtype=reorder_type)[0]\n",
        "    buffer = tr_im.read(num_images * image_rows * image_columns)\n",
        "    images = np.frombuffer(buffer, dtype = np.uint8).astype(np.float32)\n",
        "    images = np.reshape(images, (num_images, 28,28))\n",
        "    images = images/255\n",
        "    images = torch.tensor(images)   \n",
        "    tr_im.close()\n",
        " \n",
        "    tr_lb_way = way+'t10k-labels-idx1-ubyte.gz'\n",
        "    tr_lb = gzip.open(tr_lb_way,'r')\n",
        "    label_magic_number = np.frombuffer(tr_lb.read(4), dtype=reorder_type).astype(np.int64)[0]\n",
        "    num_labels = np.frombuffer(tr_lb.read(4), dtype=reorder_type).astype(np.int64)[0]\n",
        "    buffer = tr_lb.read(num_labels)\n",
        "    labels = np.frombuffer(buffer, dtype = np.uint8)\n",
        "    labels = torch.tensor(labels, dtype = torch.long)\n",
        "    tr_lb.close()\n",
        "\n",
        "    permutation = np.random.permutation(len(labels)) \n",
        "    images = images[permutation] \n",
        "    labels = labels[permutation]\n",
        "\n",
        "    for i in range(len(labels)):    \n",
        "      images[i] = rotate(images[i])\n",
        "      images[i] = noise(images[i])\n",
        "      \n",
        "    return images,labels"
      ],
      "metadata": {
        "id": "RYtVqXqFM-j0"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch(images,labels,bath_size,i):\n",
        "    bath_im = np.zeros((bath_size))\n",
        "    bath_lb = np.zeros((bath_size))\n",
        "    bath_im = np.array(images[(i*bath_size):((i+1)*bath_size)]) \n",
        "    bath_lb = np.array(labels[(i*bath_size):((i+1)*bath_size)])\n",
        "    bath_im = torch.tensor(bath_im)\n",
        "    bath_lb = torch.tensor(bath_lb)\n",
        "    return bath_im, bath_lb     \n"
      ],
      "metadata": {
        "id": "ciHmfTTlSjeh"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def noise(im):\n",
        "    noise = np.random.normal(loc = 0.5 , scale = 0.1, size = im.shape)\n",
        "    imr = np.clip(im + noise, 0, 1)\n",
        "    return imr"
      ],
      "metadata": {
        "id": "T1JbL4U3RmiG"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rotate(im):\n",
        "    deg = random.randint(0,360)\n",
        "    h,w = im.shape\n",
        "    c = 3\n",
        "    h2,w2,c2 = h//2,w//2,c//2\n",
        "    np.array([[-w2,w2,w2],[h2,h2,-h2]])\n",
        "    wr2,hr2 = (np.max(np.abs(rot_mat(deg) @ np.array([[-w2,w2,w2],[h2,h2,-h2]])),axis=1)).astype(np.int32)\n",
        "    wr,hr = wr2*2,hr2*2\n",
        "    imr = np.zeros((hr,wr))\n",
        "    yr,xr = np.indices((hr,wr))\n",
        "    yr,xr = yr.flatten(),xr.flatten()\n",
        "    yrc,xrc = yr-hr2,xr-wr2\n",
        "    xc , yc = (rot_mat(-deg) @ np.row_stack((xrc,yrc))).astype(np.int32)\n",
        "    x,y = xc+w2,yc+h2\n",
        "    include = np.logical_and(np.abs(xc)<w2,np.abs(yc)<h2)\n",
        "    imr[yr[include],xr[include]] = im[y[include],x[include]]\n",
        "    new_img = cv2.resize(imr, (28, 28) )\n",
        "    new_img = torch.tensor(new_img)  \n",
        "    return new_img\n",
        "\n",
        "def rot_mat(deg):\n",
        "    theta = deg/180*np.pi\n",
        "    c,s = np.cos(theta),np.sin(theta)\n",
        "    return np.array([[c,-s],[s,c]])"
      ],
      "metadata": {
        "id": "yYaxUvx-Pudi"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        " \n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "mtWA4wmomL4-"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loader =(train_images, train_labels) = read_train()\n",
        "test_loader =(test_images, test_labels) = read_test()\n",
        "\n",
        "training_batch_size = 50\n",
        "test_batch_size = 1000\n",
        "\n",
        "num_epochs = 25\n",
        "\n",
        "neural_net = NeuralNet()\n",
        "\n",
        "train_losses = []\n",
        "train_counter = []\n",
        "test_accuracy = []\n",
        "test_losses= []\n",
        "\n",
        "test_counter = [num * 60000 for num in range(num_epochs + 1)] \n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "learning_rate = .2\n",
        "momentum = .9\n",
        "\n",
        "optimizer = torch.optim.SGD(neural_net.parameters(), lr = learning_rate, momentum = momentum)\n",
        "\n",
        "random_seed = 1\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.manual_seed(random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAKl_OvAmNsE",
        "outputId": "de67a729-79c9-4f5a-ab2e-4bbcf592916e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb9086343b0>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "     for batch_idx in range(60000//training_batch_size): \n",
        "        images,labels = batch(train_images,train_labels,training_batch_size,batch_idx)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = neural_net(images)\n",
        "\n",
        "        loss = F.nll_loss(output, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * training_batch_size, 60000,\n",
        "                    100 * batch_idx / len(training_loader), loss.item()))\n",
        "            train_losses.append(loss.item())\n",
        "            train_counter.append((batch_idx * training_batch_size) + ((epoch - 1) * 60000)) "
      ],
      "metadata": {
        "id": "iMcIESzZLv6_"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    test_loss = 0\n",
        "    correct_guesses = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx in range(10000//test_batch_size): \n",
        "            images,labels = batch(test_images,test_labels,test_batch_size,batch_idx)\n",
        "\n",
        "            output = neural_net(images)\n",
        "            \n",
        "            test_loss += F.nll_loss(output, labels).item()\n",
        "            \n",
        "            guesses = torch.max(output, 1, keepdim = True)[1]\n",
        "\n",
        "            correct_guesses += torch.eq(guesses, labels.data.view_as(guesses)).sum()\n",
        "\n",
        "        test_loss /= len(test_loader.dataset)/test_batch_size\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        current_accuracy = float(correct_guesses)/float(10000)\n",
        "        test_accuracy.append(current_accuracy)\n",
        "\n",
        "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "                test_loss, correct_guesses,10000,\n",
        "                100. * current_accuracy)) "
      ],
      "metadata": {
        "id": "sFXfPITnMZtn"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    test()\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        train(epoch)\n",
        "        test()\n",
        "    #test()\n",
        "\n",
        "    print('Total epochs: {}'.format(num_epochs))\n",
        "    print('Max Accuracy is: {}%'.format(round(100*max(test_accuracy), 2)))\n",
        "\n",
        "    fig = plt.figure()\n",
        "    plt.plot(train_counter, train_losses, color = 'blue', zorder = 1)\n",
        "    plt.scatter(test_counter, test_losses, color = 'red', zorder = 2)\n",
        "    plt.scatter(test_counter, test_accuracy, color = 'green', marker = '+', zorder = 3)\n",
        "    plt.legend(['Train Loss', 'Test Loss', 'Accuracy'], loc = 'upper right')\n",
        "    plt.xlabel('number of training examples seen')\n",
        "    plt.ylabel('negative log likelihood loss')\n",
        "    fig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "8nUB9R69P_zq",
        "outputId": "09d4a9b0-9929-4a95-a397-7c72a6490669"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-a76a41ad9b4b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-69-bab0ab914d90>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneural_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-f77be736e457>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [10, 1, 5, 5], expected input[1, 1000, 28, 28] to have 1 channels, but got 1000 channels instead"
          ]
        }
      ]
    }
  ]
}